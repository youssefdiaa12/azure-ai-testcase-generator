
# ğŸ¤– AI Test Case Generator for Azure DevOps

Automated test case generation using **Gemini AI** with direct integration into **Azure DevOps Test Plans**.

This project reads User Stories from Azure Boards, generates highâ€‘quality manual test cases using AI, and automatically publishes them into Azure DevOps Test Plans using the latest REST APIs.

***

## ğŸš€ What the System Does

The pipeline automatically:

### âœ… Creates Test Artifacts

| Work Item      | Test Artifact |
| -------------- | ------------- |
| **Epic**       | Test Plan     |
| **Feature**    | Test Suite    |
| **User Story** | Test Cases    |

### âœ… Generates AIâ€‘Powered Test Cases

For every new User Story, the pipeline:

*   Sends acceptance criteria to Gemini AI
*   Generates wellâ€‘structured test cases
*   Normalizes and validates AI output
*   Builds proper Azure DevOps testâ€‘step XML
*   Publishes the Test Case work item
*   Links it to the Suite & Story

### âœ… Uses Modern Azure DevOps APIs

*   Creates Test Case work items
*   Adds them to test suites using the **testplan** API
*   Links them back to the parent User Story

### ğŸ§  Key Enhancements Based on Latest Change

The generator now includes:

#### âœ” AI Output Normalization

Ensures `steps` and `expected` are always clean strings (even if AI outputs lists or objects).

#### âœ” Valid Test Step XML

ADO requires **raw XML tags**, not HTML entities. Now uses:

```xml
<steps>
  <step>
    <parameterizedString>Action</parameterizedString>
    <parameterizedString>Expected</parameterizedString>
  </step>
</steps>
```

#### âœ” New "testplan" API for Suite Linking

Replaces the old-style `/test/Plans/...` endpoint with:

    POST /_apis/testplan/Plans/{planId}/Suites/{suiteId}/TestCase

#### âœ” Strong Error Handling & Logging

*   Perâ€‘case failure logs
*   Response code validation
*   HTTP timeouts
*   Payload debugging on error

***

## ğŸ— Architecture Overview

    Epic       â†’ Test Plan
    Feature    â†’ Test Suite
    User Story â†’ Test Cases

The hierarchy is automatically maintained so your tests always follow your work structure.

***

## ğŸ”„ Full Automation Flow

1.  Pipeline runs on a schedule (daily by default)
2.  Fetches **new User Stories** using WIQL
3.  For each story:
    *   Identify parent Feature
    *   Identify parent Epic
    *   Ensure Test Plan & Suite exist
    *   Send acceptance criteria to Gemini
    *   Normalize and validate AI response
    *   Build Azure DevOps Test Case XML
    *   Create Test Case Work Item
    *   Add it to the correct Test Suite
    *   Link it back to the User Story

***

## ğŸ§© AI Prompt Engineering

Gemini receives structured input:

*   Cleaned acceptance criteria
*   Scenario-separated formatting
*   Strict schema instructions
*   A required JSON array format

The AI is forced to return:

```json
{
  "title": "...",
  "type": "positive | negative | edge",
  "steps": ["..."],
  "expected": "..."
}
```

The generator then validates & normalizes this before generating XML.

***

## ğŸ›  Tech Stack

*   **Python 3.11**
*   **Azure DevOps REST API (wit + testplan)**
*   **Gemini AI (generateContent API)**
*   **Azure Pipelines (YAML)**
*   **WIQL**
*   **XML step builder for ADO manual test cases**

***

## ğŸ“ Folder Structure (recommended)

    /scripts
       main.py
       test_case_generator.py
       ai_prompt.py
    /readme.md
    /pipeline.yml

***

## ğŸ§ª Output Example in Azure DevOps

Each generated Test Case appears with:

*   Title
*   Assigned To
*   Tags (â€œAI\_Generatedâ€)
*   Autoâ€‘generated steps
*   Linked parent story
*   Linked test suite and plan

***

## ğŸ¯ Benefits

*   Consistent, high-quality test coverage
*   Zero manual effort for test creation
*   Strong alignment between Dev & QA
*   Standardized test structure across all projects
*   Works fully from Azure Pipelines with no local execution required

***
